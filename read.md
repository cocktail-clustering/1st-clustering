# wholesale-clustering

## Purpose

- Clasifying sales data with given 8 features and giving appropriate sales idea with the result.
- Use unsupervised learning â€“ Hierarchical Clustering, DBSCAN, K-Means Clustering.

## Methods

1. load data
2. check missing value
    - As there was no missing value, skipped this step. 
3. preprosessing 

    - numeric feature
        - normalization
            - For numeric features, there are some well known data preprosessing, standardlization and normalization.
            - Our numeric features need to be normalized so we used minmax scaler for min-max normalization. 
        - outliers
            - After normalization, we check byplot of each features and we can find out there are some outliers-based on IQR.
            - So we replaced outliers with Q3 value(75% of max value) of each feature. 

    - categorical feature
        - Use one-hot encoding to train machine learning model.

4. Finding Optimal k
    - Elbow Method
    - Silhoutte Coefficient
        - To find our optimal K, we used 2 methods mentioned above. 
        - For k in range 2 to 15, we drawed graph to check it visually.
        - Through these two method, we could get Optimal K = 6 in common. 

5. Clustering with 6 clusters
    - Use Kmeans, DBSCAN, Hierarchical clustering to clustering data.
    - Preceed clustering with k = 6.
    - There are 2 nominal features, Region and Channel, and we can get 6 combinations from those features.
    - And we now can see that those 6 combinations corrrspond to 6 labels one-on-one.

## Results

- 6 clusters are created.
- explain each cluster here.